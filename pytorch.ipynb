{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/sanchitnevgi/.cache/torch/hub/pytorch_vision_master\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/sanchitnevgi/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6b405b5134a14a1ff1fbc65807e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet18_model = hub.load(\"pytorch/vision:master\", \"resnet18\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PyTorch defaults to an immediate execution model (eager mode). The underlying instructions are immediately run on C++\n",
    "2. *TorchScript* is used to serialize a model into independent functions (for production use)\n",
    "3. *ONNX* is a standard vendor-agnostic format for model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Tensors\n",
    "\n",
    "1. PyTorch tensors or NumPy arrays, on the other hand, are views over (typically) **contiguous memory blocks** containing **unboxed** C numeric types rather than Python objects\n",
    "2. Each element is a 32-bit, 4 byte float\n",
    "3. Indexing\n",
    "    1. `tensor[1:2,5:6]`\n",
    "4. Named Tensors\n",
    "5. By default, tensors are `float32` or `int64`\n",
    "6. A `Tensor` is a view of a `torch.Storage` instance. Multiple tensors can index the same storage even if they index into the data differently.\n",
    "7. Using `Storage` makes some operations like *transpose*, *slicing* inexpensive as there is no memory re-allocation.\n",
    "8. Changing the subtensor will have a side effect on the original tensor\n",
    "9. Contiguous memory is more efficient (data locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4631, 0.9883, 0.8731, 0.0668, 0.9128],\n",
       "        [0.9470, 0.3323, 0.7959, 0.9149, 0.6834],\n",
       "        [0.3909, 0.6917, 0.5042, 0.1998, 0.4877],\n",
       "        [0.0207, 0.7719, 0.8862, 0.6709, 0.0439]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4, 5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of a tensor\n",
    "tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3323, 0.7959, 0.9149],\n",
       "        [0.6917, 0.5042, 0.1998]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor Indexing\n",
    "tensor[1:-1,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4631, 0.9883, 0.8731, 0.0668, 0.9128],\n",
       "         [0.9470, 0.3323, 0.7959, 0.9149, 0.6834],\n",
       "         [0.3909, 0.6917, 0.5042, 0.1998, 0.4877],\n",
       "         [0.0207, 0.7719, 0.8862, 0.6709, 0.0439]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a new dimension to the tensor. Same as tensor.unsqueeze()\n",
    "tensor[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5427,  1.3242,  1.2242,  0.3213],\n",
       "         [ 0.5507, -0.9032, -0.7180, -1.8293],\n",
       "         [-1.1005,  2.0100, -2.0273, -1.9066],\n",
       "         [ 0.7365, -0.5707, -1.4878,  0.0032]],\n",
       "\n",
       "        [[-0.6709, -0.9744,  1.7123, -1.1352],\n",
       "         [-0.7160, -2.4199,  0.2918,  0.2005],\n",
       "         [-0.0837,  0.2023, -0.4316, -0.3629],\n",
       "         [-0.3429,  1.8585,  1.4647, -0.5072]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named tensors\n",
    "img_t = torch.randn(2, 4, 4)\n",
    "img_t_named = img_t.refine_names(..., \"channels\", \"width\", \"height\")\n",
    "\n",
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9128,  0.7514, -0.2208,  1.4657],\n",
       "         [-0.5490,  0.0058, -0.4195,  0.6694],\n",
       "         [ 0.9004,  0.9597,  0.0488,  1.7796]],\n",
       "\n",
       "        [[-0.5128,  1.5673, -1.3727,  0.2322],\n",
       "         [ 0.5986, -1.2913, -1.6881,  0.2693],\n",
       "         [-0.1088, -1.2981, -0.1335, -0.4401]]],\n",
       "       names=('channels', 'width', 'height'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of defining named tensors\n",
    "img_r = torch.randn(2, 3, 4, names=[\"channels\", \"width\", \"height\"])\n",
    "img_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaligned:  torch.Size([2])\n",
      "Aligned:  torch.Size([2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Align a tensor to the names of another\n",
    "weights_named = torch.randn(2, names=[\"channels\"])\n",
    "print(\"Unaligned: \", weights_named.size())\n",
    "\n",
    "weights_aligned = weights_named.align_as(img_r)\n",
    "print(\"Aligned: \", weights_aligned.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any function with dimension argument, takes the name as well\n",
    "img_r.sum(\"channels\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9128,  0.7514, -0.2208,  1.4657],\n",
       "         [-0.5490,  0.0058, -0.4195,  0.6694],\n",
       "         [ 0.9004,  0.9597,  0.0488,  1.7796]],\n",
       "\n",
       "        [[-0.5128,  1.5673, -1.3727,  0.2322],\n",
       "         [ 0.5986, -1.2913, -1.6881,  0.2693],\n",
       "         [-0.1088, -1.2981, -0.1335, -0.4401]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset names\n",
    "img_r.rename(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer tensors by default are int64\n",
    "int_tensor = torch.tensor([2, 2])\n",
    "int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float tensors are float32 by default\n",
    "float_tensor = torch.tensor([1.0, 1.0])\n",
    "float_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.int16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting dtype on initialization\n",
    "ones = torch.ones(5, 4, dtype=torch.short)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting to dtype\n",
    "ones.double()\n",
    "ones.to(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor API\n",
    "Refer the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A storage is always 1 dimensional\n",
    "torch.Storage([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.LongStorage of size 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access the underlying storage\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the storage, changes all the tensors viewing it\n",
    "tensor.storage()[0] = 4\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some tensors have special methods with trailing underscores (zero_). \n",
    "# This means that they perform in-place operation. Otherwise they return a new tensor\n",
    "tensor.zero_()\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 0],\n",
      "        [4, 4, 0],\n",
      "        [1, 3, 1]])\n",
      "stride:  (3, 1)\n",
      "offset:  0\n"
     ]
    }
   ],
   "source": [
    "# A tensor has metadata - size, offset, and stride; to properly index into the storage\n",
    "tensor = torch.randint(0, 5, size=(3, 3))\n",
    "print(tensor)\n",
    "print(\"stride: \", tensor.stride())\n",
    "print(\"offset: \", tensor.storage_offset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) 3\n"
     ]
    }
   ],
   "source": [
    "row = tensor[1]\n",
    "print(row.stride(), row.storage_offset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  0],\n",
       "        [10,  4,  0],\n",
       "        [ 1,  3,  1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing a sub-tensor will modify the original tensor\n",
    "row[0] = 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  4,  0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To avoid this, clone the tensor\n",
    "row_clone = tensor[1].clone()\n",
    "row_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [1, 3, 2]])\n",
      "tensor([[1, 1],\n",
      "        [0, 3],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "a = torch.randint(0, 4, size=(2, 3))\n",
    "print(a)\n",
    "print(a.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explicitly make the tensor contiguous\n",
    "print(a.t().is_contiguous())\n",
    "b = a.t().contiguous()\n",
    "a.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same storage: True\n",
      "(1,) (3, 1)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(list(range(9)))\n",
    "b = a.view(3, 3)\n",
    "print(\"Same storage:\", id(a.storage()) == id(b.storage()))\n",
    "print(a.stride(), b.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the device argument to specify a device\n",
    "# gpu_tensor = torch.ones(10, 5, device=\"cuda\")\n",
    "\n",
    "# Move to the gpu\n",
    "# gpu_tensor = torch.ones(10, 5).to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Real-world data representation using tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
